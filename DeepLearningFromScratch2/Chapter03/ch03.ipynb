{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter03 word2vec\n",
    "이번 장에는 추론 기반 기법을 사용한다.  \n",
    "추론 과정에서 신경망을 사용하고, 여기서 word2vec이 등장.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 추론 기반 기법과 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 통계 기반 기법의 문제점\n",
    "어휘가 100만개면 100만*100만 의 행렬을 계산해야 한다. 여기에 SVD를 적용하는건 무리다.  \n",
    "(SVD의 복잡도는 O(n**3))  \n",
    "통계기반기법은 데이터를 한번에 처리한다(batch). 추론기반기법은 조금씩 쓴다(minibatch)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 추론 기반 기법 개요\n",
    "추론: 주변 단어(맥락)이 주어졌을 때, 빈칸의 단어를 추측하는 작업.  \n",
    "ex: \"you [   ] goodbye and i say hello\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 신경망에서의 단어 처리\n",
    "단어를 one hot vector로 변환. \n",
    "index가 단어 id와 같으면 1, 아니면 0.  \n",
    "이런 방법으로 입력의 크기를 고정한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.47167304  0.96859856 -1.29090961]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "C = np.array([1, 0, 0, 0, 0, 0, 0]) #input\n",
    "W = np.random.randn(7, 3)           #weight\n",
    "h = np.matmul(C, W)                 #hidden node\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C is one hot vector.  \n",
    "thus, C*W means we extracted single row from W."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.56953879  0.03512242 -0.51395428]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.layers import MatMul\n",
    "\n",
    "c = np.array([1, 0, 0, 0, 0, 0, 0])\n",
    "W = np.random.randn(7,3)\n",
    "layer = MatMul(W) #?\n",
    "h = layer.forward(c)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 simple word2vec\n",
    "we are going to use CBOW(Continuous bag-od-words) for neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 CBOW model's inference process\n",
    "target word: blank words.  \n",
    "context: words around target word  \n",
    "we use multiple inputs. N words for context => N inputs  \n",
    "hidden layer's input will be (h1 + h2)/N   \n",
    "output layer's neuron are map of our words.  \n",
    "W(in) is distributed expression of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.22177788e+00  1.04258115e-01  1.05141753e+00 -1.94352697e-03\n",
      "  -1.96416889e+00  2.98756978e-01 -8.24743898e-01]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.layers import MatMul\n",
    "\n",
    "#sample context data\n",
    "c0 = np.array([[1, 0, 0, 0, 0, 0, 0]])\n",
    "c1 = np.array([[0, 0, 1, 0, 0, 0, 0]])\n",
    "\n",
    "#initializing weights\n",
    "W_in = np.random.randn(7,3)\n",
    "W_out = np.random.randn(3, 7)\n",
    "\n",
    "#계층 생성\n",
    "in_layer0 = MatMul(W_in)\n",
    "in_layer1 = MatMul(W_in)\n",
    "out_layer = MatMul(W_out)\n",
    "\n",
    "#순전파\n",
    "h0 = in_layer0.forward(c0)\n",
    "h1 = in_layer1.forward(c1)\n",
    "h = 0.5 * (h0 + h1)\n",
    "s = out_layer.forward(h)\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 CBOW's training\n",
    "we use softmax and CEE to measure loss.  \n",
    "(skip-gram is our model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 word2vec's weight and distributed expression\n",
    "W_in has information of words.  (7 x 3)  \n",
    "W_out also has information of words. in column (3 x 7)  \n",
    "what do we use?  we could use both of them. simply get mean.  \n",
    "we will use W_in. which is common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
